
The evaluation results have been obtained using the standard and most commonly used MIR's tools and frameworks such as default values of MSAF \cite{MSAF} for the segmentation algorithms \cite{sf}, the SALAMI dataset \cite{Smith2011DESIGNANNOTATIONS} as evaluation ground truth and $mir_eval$ \cite{RaffelMir_eval:METRICS} for metric computation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[h]
\centering
\begin{tabularx}{\textwidth}{|X|X|X|X|X|}
\hline
\textbf{Technique} & \textbf{Training Dataset} & \textbf{Precision} & \textbf{Recall} & \textbf{F-measure} \\
\hline
MFCC & -- & 0.173 & 0.185 & 0.172 \\
\hline
Embeddiogram & GTZAN Dataset & 0.228 & 0.171 & 0.185 \\
\hline
Embeddiogram & MSD Dataset & \textbf{0.335} & 0.276 & 0.288 \\
\hline
PCP & -- & 0.311 & 0.324 & 0.305 \\
\hline
Tonnetz & -- & 0.312 & 0.312 & 0.300 \\
\hline
CQT & -- & 0.311 & \textbf{0.339} & \textbf{0.312} \\
\hline
\end{tabularx}
\caption[Comparison of precision, recall, and f-measure for different audio features]{Comparison of precision, recall, and f-measure for different features obtained using the SF algorithm \cite{sf} on the SALAMI dataset. Sliding windowed segments across the audio signal input signal is 4 seconds}
\label{tab:comparison}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[h]
\centering
\small
\begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}p{4.5cm}XXXXX}
\toprule
\thead{\centering\textbf{Authors [Ref], Year}} & \thead{\centering\textbf{Input}} & \thead{\centering\textbf{Method}} & \thead{\centering\textbf{F-measure}} \\
\midrule
\addlinespace
Kaiser et al. \cite{27}, 2012 & SSM & Novelty measure  & 0.286 \\
\addlinespace
McFee \& Ellis \cite{20}, 2013 & MLS & Fisher’s Linear Discriminant  & 0.317 \\
\addlinespace
Nieto \& Bello \cite{28}, 2014 & MFCCs, chromas & Checkerboard-like kernel  & 0.299 \\
\addlinespace
Cannam et al. \cite{29}, 2015 & Timbre-type histograms & HMM  & 0.213 \\
\addlinespace
Nieto \cite{30}, 2016 & Constant-Q Transform Spectrogram & Linear Discriminant Analysis  & 0.299 \\
\addlinespace
Cannam et al. \cite{29}, 2017 & Timbre-type histograms & HMM  & 0.212 \\
\addlinespace
Turnbull et al. \cite{Turnbull2007ABOOSTING}, 2007 & MFCCs, chromas, spectrogram & Boosted Decision Stump  & 0.378 \\
\addlinespace
Sargent et al. \cite{34}, 2011 & MFCCs, chromas & Viterbi  & 0.356 \\
\addlinespace
Ullrich et. al \cite{22}, 2014 & MLS & CNN  & 0.465 \\
\addlinespace
Grill \& Schlüter \cite{4}, 2015 & MLS, SSLMs & CNN  & \textbf{0.523} \\
\addlinespace
Grill \& Schlüter \cite{GrillMUSICANNOTATIONS}, 2015 & MLS, PCPs, SSLMs & CNN  & 0.508 \\
\addlinespace
Hadria \& Peeterss \cite{35}, 2017 & MLS, SSLMs & CNN  & 0.291 \\
\bottomrule
\end{tabularx}
\caption[Baseline. State-of-the-art table.]{\small{Previous studies' boundary detection f-measure results using \textbf{unsupervised} methods for a 0.5s time-window tolerance. Only the top-performing algorithm for each year on the SALAMI dataset is displayed. Original source \cite{Hernandez-Olivan2021MusicFeatures}}}
\label{tab:comparison_table}
\end{table}