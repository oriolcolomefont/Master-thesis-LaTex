
SALAMI (Structural Analysis of Large Amounts of Music Information) is a project aiming to carry out extensive structural analyses on a wide variety of music, from Western pop to Indian classical, and from live to studio recordings \cite{Smith2011DESIGNANNOTATIONS}. Instead of traditional forms, the authors segment pieces into sections, combining perceptual, functional, and transcription analyses. Despite limitations, this approach offers a holistic and nuanced perspective on music structure.

METRICS

\begin{itemize}
    \item \textbf{Precision}: Precision measures the proportion of correctly detected boundaries out of the total estimated boundaries. It quantifies the accuracy of the boundary detection algorithm. It is calculated as:
    
    \[
    \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
    \]
    
    High precision indicates a low rate of false positives, meaning the algorithm correctly identifies boundaries without many incorrect detections.
    
    \item \textbf{Recall}: Recall measures the proportion of correctly detected boundaries out of the total reference boundaries. It quantifies the completeness or sensitivity of the boundary detection algorithm. It is calculated as:
    
    \[
    \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
    \]
    
    High recall indicates a low rate of false negatives, meaning that the algorithm successfully detects most of the true boundaries without missing many.
    
    \item \textbf{F-measure}: The F-measure is a widely used boundary detection metric computed by comparing the predicted and ground truth boundaries. This metric, ranging from 0 to 1, represents the harmonic mean of precision and recall, providing a balanced view of under-segmentation and over-segmentation. Given the potential inaccuracies in human annotations and prediction errors, the F-measure tolerates minor discrepancies between predicted and ground truth boundaries. This tolerance level can be adjusted, enabling the metric to consider a predicted boundary as correct if it's within the set tolerance window of a ground truth boundary \cite{Turnbull2007ABOOSTING}. The F-measure is calculated as follows:
    
    \[
    \text{F-measure} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
    \]
\end{itemize}

Extend table by Hernandez-Olivan, C., Beltran, J. R. \& Diaz-Guerra, D. 
\cite{Hernandez-Olivan2021MusicFeatures}

\begin{table}[h]
\centering
\small
\begin{tabularx}{\textwidth}{>{\raggedright\arraybackslash}p{4.5cm}XXXXX}
\toprule
\thead{\centering\textbf{Authors [Ref], Year}} & \thead{\centering\textbf{Input}} & \thead{\centering\textbf{Method}} & \thead{\centering\textbf{F-measure}} \\
\midrule
\addlinespace
Kaiser et al. \cite{27}, 2012 & SSM & Novelty measure  & 0.286 \\
\addlinespace
McFee \& Ellis \cite{20}, 2013 & MLS & Fisher’s Linear Discriminant  & 0.317 \\
\addlinespace
Nieto \& Bello \cite{28}, 2014 & MFCCs, chromas & Checkerboard-like kernel  & 0.299 \\
\addlinespace
Cannam et al. \cite{29}, 2015 & Timbre-type histograms & HMM  & 0.213 \\
\addlinespace
Nieto \cite{30}, 2016 & Constant-Q Transform Spectrogram & Linear Discriminant Analysis  & 0.299 \\
\addlinespace
Cannam et al. \cite{29}, 2017 & Timbre-type histograms & HMM  & 0.212 \\
\addlinespace
Turnbull et al. \cite{Turnbull2007ABOOSTING}, 2007 & MFCCs, chromas, spectrogram & Boosted Decision Stump  & 0.378 \\
\addlinespace
Sargent et al. \cite{34}, 2011 & MFCCs, chromas & Viterbi  & 0.356 \\
\addlinespace
Ullrich et. al \cite{22}, 2014 & MLS & CNN  & 0.465 \\
\addlinespace
Grill \& Schlüter \cite{4}, 2015 & MLS, SSLMs & CNN  & 0.523 \\
\addlinespace
Grill \& Schlüter \cite{GrillMUSICANNOTATIONS}, 2015 & MLS, PCPs, SSLMs & CNN  & 0.508 \\
\addlinespace
Hadria \& Peeterss \cite{35}, 2017 & MLS, SSLMs & CNN  & 0.291 \\
\bottomrule
\end{tabularx}
\caption[Baseline. State of the art table.]{Your Caption.

SALAMI dataset

}
\label{tab:my_label}
\end{table}