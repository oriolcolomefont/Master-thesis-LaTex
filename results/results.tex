\chapter{Results}

\input{results/subsections/tables}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/images/first results.png}
    \caption{Caption}
    \label{fig:boxplotmetrics}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/images/f-measure.png}
    \caption{Caption}
    \label{fig:boxplotfmeasure}
\end{figure}


The F-measure is a widely used boundary detection metric computed by comparing the predicted and ground truth boundaries. This metric, ranging from 0 to 1, represents the harmonic mean of precision and recall, providing a balanced view of under-segmentation and over-segmentation. Precision calculates the percentage of correctly detected boundaries, whereas recall assesses the percentage of actual boundaries detected correctly. Given the potential inaccuracies in human annotations and prediction errors, the F-measure tolerates minor discrepancies between predicted and ground truth boundaries. This tolerance level can be adjusted, enabling the metric to consider a predicted boundary as correct if it's within the set tolerance window of a ground truth boundary \cite{Turnbull2007ABOOSTING}.

\newpage


