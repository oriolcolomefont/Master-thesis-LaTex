\chapter{Evaluation}

\section{Music boundary detection as downstream task}

While the usefulness of deep audio embeddings can be evaluated in countless downstream tasks \cite{Li2023MERT:Training, Kim2020OneStrategies}, we have chosen music boundary detection, a subset of Music Structure Analysis (MSA) for its popularity, complexity, and product-compelling nature. This interdisciplinary field aims to understand the structure of music \cite{Nieto2020Audio-BasedApplications}. Due to subjectivity, ambiguity, and data scarcity, audio-based MSA faces challenges like boundary placement ambiguity and similarity quantification \cite{NietoPerceptualMusic}.  

All the evaluation experiments have been wrapped around MSAF \cite{NietoMSAF:FRAMEWORK}, a popular framework for Music Structure Analysis.

All the evaluation metrics have been computed using the mir-eval package \cite{RaffelMir_eval:METRICS}.

\section{The \textit{embeddiogram}, a deep audio feature representation}

The \textit{embeddiogram}, a deep audio feature representation, is derived by applying our pre-trained neural network to sliding windowed segments across the audio signal, generating a sequence of embedding vectors. These relatively low-dimensional embedding vectors collectively form a two-dimensional description of the audio signal's musical content.

Below is a detailed explanation of how we compute the \textit{embeddiogram} from a given audio signal of length $N$. This process comprises loading the audio data, slicing the audio data into windowed segments, processing each window using a pre-trained model to produce an embedding per window/time-frame, collecting and stacking these embeddings, and finally normalizing the resulting matrix or as we like to call it, \textit{embeddiogram}. 

\begin{enumerate}
\item \textbf{Load the audio data}: The audio data is loaded into memory as a one-dimensional array of length $N$.

\item \textbf{Slice the audio data}: The audio data is segmented into overlapping windows. Each window contains $w$ samples, and consecutive windows are separated by $h$. This gives a total of $H$ windows, defined as:
\begin{equation}
H = 1 + \left\lfloor \frac{N - w}{h} \right\rfloor
\end{equation}
In the case where $\left( N - w \right) \mod h > 0$, we have $H += 1$ to account for the final, potentially smaller, window.

\item \textbf{Process each window}: Each window of audio data is processed independently, passed through the pre-trained neural network model, and transformed into an embedding vector. Formally, for each window $w_i$ of audio data, we have:
\begin{equation}
\text{embedding}_i = \text{model}(w_i)
\end{equation}

\item \textbf{Collect the embeddings}: The embedding vectors are collected and stacked together. Each row represents a feature vector for a given time frame to form the \textit{embeddiogram}, denoted as $\text{e}$:
\begin{equation}
\text{e} = \begin{bmatrix} \text{embedding}_1 \\ \text{embedding}_2 \\ \vdots \\ \text{embedding}_H \end{bmatrix}
\end{equation}

\item \textbf{Normalize the \textit{embeddiogram}}: The \textit{embeddiogram} is normalized to have a minimum value of 0 and a maximum value of 1 per dimension. The normalization process is given by:
\begin{equation}
E'_{ij} = \frac{e_{ij} - \min(E)}{\max(E) - \min(E)}
\end{equation}
\end{enumerate}

\begin{figure}[ht]
  \centering
  \begin{minipage}[b]{1.0\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/images/salami_391_embeddiogram.png}
    \caption[Embeddiogram. Track 391 (SALAMI dataset).]{Embeddiogram. Track 391 (SALAMI dataset).}
    \label{fig:image1}
  \end{minipage}

  \begin{minipage}[b]{1.0\linewidth}
    \centering
    \includegraphics[width=\linewidth]{figures/images/samali_391_novelty_curve_peaks.png}
    \caption[Novelty curve + peaks. Track 391 (SALAMI dataset).]{Novelty curve + peaks. Track 391 (SALAMI dataset).}
    \label{fig:image2}
  \end{minipage}
\end{figure}


\begin{figure}[ht]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/images/salami_391_R matrix after Gaussian smoothing.png} % first figure itself
        \caption[Track 391 (SALAMI dataset) Self-similarity matrix]{Self-similarity matrix. Track 391 (SALAMI dataset).}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/images/salami_391_Lag matrix after Gaussian smoothing.png} % second figure itself
        \caption[Track 391 (SALAMI dataset) Self-similarity lag matrix]{Self-similarity lag matrix. Track 391 (SALAMI dataset).}
    \end{minipage}
    \vfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/images/salami_391_Q_matrix.png} % third figure itself
        \caption[Track 391 (SALAMI dataset). Q-matrix]{Cumulative matrix. Track 391 (SALAMI dataset).}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.9\textwidth]{figures/images/salami_391_binary transitive matrix.png} % fourth figure itself
        \caption[Track 391 (SALAMI dataset). Transitive Binary Similarity Matrix]{Transitive Binary Matrix. Track 391 (SALAMI dataset).}
    \end{minipage}
\end{figure}

\newpage