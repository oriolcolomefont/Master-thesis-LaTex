%\addcontentsline{toc}{chapter}{Abstract}

\begin{abstract}
\pagenumbering{gobble}

Music, an integral part of human culture, offers a diverse yet complex field of study due to its intricate styles, mutable ground truth, and subjective nature. This research, conducted in collaboration with Epidemic Sound AB and the Music Technology Group (MTG) at Universitat Pompeu Fabra (UPF), employs self-supervised contrastive learning of musical representation to uncover the fundamental structure of Western tonal music. 

Embracing a subtle novel approach, this process is facilitated by applying Siamese networks with a triplet loss, mimicking human aural skills in interpreting music to discern abstract and semantic musical elements, irrespective of the sonic qualities. The study replaces traditional acoustical features with deep audio embeddings to compute high-level, sound-agnostic, and content-sensitive music identification.

Results XXXXXX TBC

The preliminary results suggest that our approach to learning music-informed embeddings holds significant potential for nearly all MIR downstream tasks. Music-motivated embeddings represent a promising technique, adaptable potentially to other tasks hindered by data scarcity. This method could significantly influence advancements in intelligent music recommendation systems and the efficient enforcement of intellectual property rights. 

\bigskip
Keywords: Music Information Retrieval; Music Structure Analysis; Deep Audio Embeddings, Aural Skills

\newpage
\end{abstract}