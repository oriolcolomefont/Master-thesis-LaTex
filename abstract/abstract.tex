%\addcontentsline{toc}{chapter}{Abstract}

\begin{abstract}
\pagenumbering{gobble}

This thesis posits the existence of invariant high-level musical concepts that persist through changes in sonic qualities, akin to the symbolic domain where essence endures despite varying interpretations through different performances, instruments, and styles, among many other variables.

In collaboration with Epidemic Sound AB and the Music Technology Group (MTG) at Universitat Pompeu Fabra (UPF), we used self-supervised contrastive learning to uncover the underlying structure of Western tonal music. We applied deep convolutional neural networks and a triplet loss function, identifying abstract and semantic musical elements without relying on their sonic qualities. This way, we replaced traditional acoustic features with deep audio embeddings, paving the way for high-level, sound-agnostic, and content-sensitive music identification.

Our cognitively-based approach for learning embeddings focuses on using full-resolution data and preserving high-level musical information. Drawing upon our domain expertise, we developed robust transformations to encode heuristic musical concepts that should remain constant. This novel approach aims to reconcile music and machine learning, enhancing machine listening models' efficacy. Preliminary results suggest that our musically-informed technique has significant potential for boundary detection tasks and possibly nearly all MIR downstream tasks that are not purely sonic-based. Consequently, music-motivated embeddings appear promising and potentially adaptable to other tasks constrained by data scarcity.

\bigskip
Keywords: MIR; Music Structure Analysis; deep audio embeddings; audio representations; representation learning; embeddings; transfer learning; multi-task learning; multi-modal learning; aural Skills

\newpage
\end{abstract}