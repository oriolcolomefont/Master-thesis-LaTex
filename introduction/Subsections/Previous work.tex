\section{Related work}

Learning deep audio embeddings can somehow be considered as breaking down the essence of tonal music to its fundamental and most empirical elements. Dissecting musical structures from the most ethereal and spiritual foreground  to the foundational numerical nuances. 

It also delves into middle-ground elements and mesostructures \cite{Mesostructures2023}, bridging micro and macro structures with harmonic progressions, thematic materials, and voice-leading reductions. 

\subsection{XXXX}

Neural networks have recently facilitated the development of low-dimensional musical embeddings that capture essential musical features, enabling the computation of content-based similarity between musical passages \cite{Kim2021LearningLoss}\cite{Hung2022Feature-informedClassification}. An embedding function $f(x) \in \mathbb{R}^d$ maps a given course $x$ to a vector in the real space $\mathbb{R}^d$, allowing the measurement of similarity between two musical passages using Euclidean distance, as denoted by the formula $D_{i,j} = ||f(x_i) - f(x_j)||^2$. The success of such systems hinges on the level of musical abstraction and the embedding space's capacity to interpret music in a manner consistent with human perception. As a result, a suitable embedding space is vital for producing output that aligns with human expectations.
