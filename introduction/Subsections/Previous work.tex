\section{Related work}

Recent advancements in neural networks have enabled the development of low-dimensional embeddings which encapsulate critical musical attributes, thus facilitating the computation of diverse task-specific elements. 

Such tasks encompass developing an audio embedding method that excels across a wide array of applications without fine-tuning \cite{Turian2022HEAR:Representations}, deploying deep audio embeddings for multi-level music segmentation \cite{SalamonDeepSegmentation}, improving environmental sound classification \cite{Kim2020OneStrategies}, enhancing vocal-centric music tasks via cross-domain audio embedding \cite{Kim2021LearningLoss}, combining task-specific and pre-trained features for improved audio classification \cite{Hung2022Feature-informedClassification}, creating a music similarity search engine tailored for video producers \cite{epidemic}, enhancing Music Emotion Recognition (MER) performance \cite{KohComparisonRecognition}, investigating the efficacy of speaker recognition pre-trained model embeddings \cite{lightweight}, embedding songs for similarity comparison via artist identification \cite{contentmusicsimtriplet2020}, solving the cross-modal text-to-music retrieval issue \cite{WonEmotionStories}, and facilitating automated music rearrangement \cite{Stoller2018IntuitiveTransitions, Plachouras2023MusicSegmentation}.

Furthermore, deep learning applications in music often overlook the intermediate-level musical patterns, analogous to the 'mesostructure' in music and the middle ground in Schenkerian analysis. As highlighted by \cite{Mesostructures2023}, addressing this mesostructure could significantly improve tasks like music analysis, composition, and retrieval by providing a more holistic understanding of music, comparable to insights from Schenkerian analysis \cite{Introduction_to_Schenkerian_Analysis}.

Additionally, deep audio embeddings offer the benefit of transferability, acting as a starting point for various tasks, thus saving computational resources and time as opposed to training a model from scratch \cite{HamelTransferSimilarity}.

However, it is still an open question whether a general-purpose audio representation can effectively mimic human hearing \cite{Turian2022HEAR:Representations}.

Considering their proven efficacy in existing literature and their potential for transfer learning, it appears promising to further investigate deep audio embeddings for Music Information Retrieval (MIR) downstream tasks.
