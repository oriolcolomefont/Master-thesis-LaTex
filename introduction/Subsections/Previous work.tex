\section{Related work}

Previous studies have highlighted the significance of selecting suitable audio features to distinguish and label unique music segments in music segmentation tasks. However, acquiring music segment annotation data for learning feature transformations presents a challenge due to its labor-intensive and expensive nature. Research has leveraged unsupervised deep learning to mitigate this, using readily available music audio. This methodology has significantly enhanced the efficacy of segmentation algorithms, yielding state-of-the-art results. Furthermore, strategies that recognize the hierarchical nature of the structural organization employing two-level annotations of primary and secondary boundaries have further augmented boundary detection performance \cite{unsupervisedlearndeepfeat, GrillMUSICANNOTATIONS, Hernandez-Olivan2021MusicFeatures, SalamonDeepSegmentation}.

Apart from music structure applications, recent advances in neural networks have facilitated the generation of low-dimensional numerical representations that encapsulate key musical attributes. This development simplifies the computation of various task-specific elements. Such tasks encompass:

\begin{itemize}
\item Developing an audio embedding method that excels across numerous applications without the need for fine-tuning \cite{Turian2022HEAR:Representations}
\item Enhancing environmental sound classification \cite{Kim2020OneStrategies, CramerLOOKEMBEDDINGS}
\item Improving vocal-centric music tasks via cross-domain audio embeddings \cite{Kim2021LearningLoss}
\item Merging task-specific and pre-trained features to improve audio classification \cite{Hung2022Feature-informedClassification}
\item Designing a music similarity search engine for video producers \cite{epidemic}
\item Augmenting Music Emotion Recognition (MER) performance \cite{KohComparisonRecognition}
\item Investigating the efficacy of speaker recognition pre-trained model embeddings \cite{lightweight}
\item Embedding songs for similarity comparison via artist identification \cite{contentmusicsimtriplet2020}
\item Addressing the cross-modal text-to-music retrieval issue \cite{WonEmotionStories}
\item Facilitating automated music rearrangement \cite{Stoller2018IntuitiveTransitions, Plachouras2023MusicSegmentation}
\end{itemize}

Moreover, deep audio embeddings provide the advantage of transferability, serving as a basis for multiple tasks. This approach conserves computational resources and time compared to training a model from scratch \cite{HamelTransferSimilarity}.

Given their demonstrated effectiveness in existing literature and their potential for transfer learning, deep audio embeddings hold substantial promise for MIR downstream tasks, specifically boundary detection. Nevertheless, it remains uncertain whether a general-purpose audio representation can effectively replicate human hearing \cite{Turian2022HEAR:Representations}, even though some techniques have managed to generalize across up to fourteen music understanding tasks \cite{Li2023MERT:Training}.