\section{Objectives}

This study explores music's high-level tonal structure by leveraging self-supervised deep neural networks, inductive bias, and aural skills to learn and analyze music embeddings applicable to subsequent MIR tasks. 

The study aims to develop a unified numerical understanding (or embedding \footnote{A learned representation or embedding is a numerical output -usually a fixed-size vector- produced by a machine-learning model. Good representations should be versatile across various tasks and require limited supervision \cite{Turian2022HEAR:Representations}.}) for a music piece that integrates high-level elements like melody contour, harmony relationships, and other comprehensive components such as the relationships between elements unfolding through time, arranging the embedding space to emphasize the clustering of these sophisticated musical content without considering sonic qualities or attributes. 

The research will utilize MIR computational methodologies and musicological perspectives to explore musical compositions from various styles and genres. 

This approach seeks to replicate human auditory capabilities in understanding and identifying abstract and semantic musical elements independent of their sonic qualities.