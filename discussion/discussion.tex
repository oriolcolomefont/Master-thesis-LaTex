\chapter{Conclusions}

\section{Conclusions}

In this work, we introduced a method that leverages self-supervised deep neural networks to learn low-dimensional music latent representations with applications to music boundary detection tasks. Building on existing approaches and architectures, we replaced traditional features with deep embeddings trained to represent high-level musical information to analyze its performance in music segmentation tasks.

While our musically-informed technique does not yet outperform the existing state-of-the-art baselines, it exhibits significant potential in boundary detection tasks, particularly when expanding the training set. The improvement we've observed between datasets is noteworthy, and when compared with two of the acoustic features, our results are highly competitive. 

We have also managed to circumvent the typical issues associated with dataset enlargements, such as the need for extensive supervision or human annotation, which gives our method an edge in terms of practicality and scalability, effectively turning what is usually seen as an expensive hurdle into a much more manageable task.

\section{Discussion}

One of the main reasons why \cite{deepfeaturesegment, SalamonDeepSegmentation} might outperform our method might be their task-tailored and MSA-focused designs specifically oriented towards music segmentation. In contrast, our method aims to be broader and more abstract, which may present a downside when evaluating specific tasks.

Whether our model effectively decodes underlying high-level musical content remains open to scientific investigation. It's plausible that our technique possesses significant potential for nearly all content-based MIR downstream tasks, given its intention to be both sound-agnostic and content-sensitive. Queries persist about whether such a general-purpose audio representation can mimic human hearing \cite{Li2023MERT:Training, Turian2022HEAR:Representations}, or if it can accurately decode high-level musical content. Such questions remain unresolved due to the current lack of evaluative measures. 

We argue whether factors such as the size of the representation layer and the size of the model \cite{verydeep} might be insufficient. Furthermore, we posit that the loss function could decrease further with additional time to iterate repeatedly over the stochastic and never-ending dataset.

The proposed embeddiograms are a promising new approach for music boundary detection. While they do not yet rival state-of-the-art methods, they are competitive with traditional handcrafted signal processing methods and can be trained on unlabeled audio files. This makes them a cost-effective and scalable solution for music boundary detection tasks.

\newpage


