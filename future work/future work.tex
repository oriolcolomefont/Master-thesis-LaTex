\chapter{Future Work}

The question as per \cite{Turian2022HEAR:Representations} or \cite{Li2023MERT:Training} remains if such general-purpose audio representation can mimic human hearing. That is a "thorn in our side" that we will pursue.

transforms
stems
different takes
k-fold cross validation
hyper-params: kernel size 0.005 times the sample rate

Utilize the dB-scale Mel-spectrum magnitude of audio as input data; it is a popular choice for input representation in music-related tasks when applying CNNs, as has been demonstrated in various studies \cite{Kim2020OneStrategies}. In addition to their wide usage, it's been recently reported that their frequency-domain summarization, grounded in psycho-acoustics, is efficient and challenging to replicate through solely data-driven methods. \cite{Kim2020OneStrategies}

Visual and listening evaluation: 2D or 3D latent space visualization as per \ref{fig:manifold}. Arranging the embedding space in a visual display to evaluate the clustering of this sophisticated musical content to see to what extent they consider sonic attributes. 

\input{figures/neural networks/manifold}

\newpage