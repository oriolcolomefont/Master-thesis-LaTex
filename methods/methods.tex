\chapter{Methods}

We propose the use of a triple siamese network to train a model for music similarity retrieval. Specifically, we aim to minimize the loss function between the anchor, positive, and negative samples by using online triplet mining.

The positive samples are created by transforming and augmenting the original samples while preserving their perceptual underlying musical language. This is achieved by using techniques such as time-stretching, pitch-shifting, and adding noise to the samples. By doing so, we aim to enhance the diversity of the positive samples and improve the model's ability to retrieve similar-sounding samples that share the same underlying musical language.

On the other hand, the negative samples are created by shuffling and scrambling the original samples while maintaining their production texture. This is achieved by using techniques such as random segment selection, time-domain filtering, and frequency-domain masking. The goal is to maintain the production texture of the samples while disrupting their underlying composition.

By using the proposed triple siamese network and online triplet mining, we aim to train a model that can effectively distinguish between similar and dissimilar samples while taking into account both their underlying composition and production texture.

\section{Materials}

\section{Convolutional Neural Network (CNN)}

A Convolutional Neural Network (CNN), is a deep-learning neural network. The architecture of a CNN is composed of several layers, including:

\begin{itemize}

\item Convolutional layers: These layers apply a convolution operation to the input data, effectively learning local patterns and features in the image. The raw audio data is typically transformed into a spectrogram or a Mel-spectrogram representation, which can be considered an image-like 2D representation of the audio data. The convolutional layers are designed to learn local patterns and features in the audio data
\vspace*{3mm}

\item Pooling layers: These layers downsample the data, reducing the spatial dimensions of the input while retaining important information. They can also be used to downsample the data and reduce the temporal dimensions of the input while retaining important information. 
\vspace*{3mm}

\item Fully connected layers: These layers connect every neuron in one layer to every neuron in another layer, allowing the network to learn non-linear combinations of the features learned in the previous layers.
\vspace*{3mm}

\item Output layer: The output layer produces the final predictions of the network.
\end{itemize}

Compared to a traditional neural network, CNNs are more computationally efficient and have less number of parameters to train. This makes them more feasible for large-scale datasets and real-world problems.

On top of that, one of the main advantages of using CNNs for audio analysis is that they can automatically and adaptively learn temporal hierarchies of features from audio data, which traditional audio processing methods may not be able to do effectively. 

\subsection{Neural Network (NN)}

%Single
\input{Figures/Figures CNN/Single Neuron}
%NN
\input{Figures/Figures CNN/Network_graph}

%Backpropagation
\input{Figures/Figures CNN/Multi-layer_NN}

%CNN
A high-level illustration of a simple convolutional neural network indicating convolutional layers, pooling layers, and fully-connected layers without details (number of channels or neurons per layer or the input image size) can be seen in XXX.
\input{Figures/Figures CNN/CNN_diagram}

%Single CNN
\input{Figures/Figures CNN/Single_CNN}

%Single pooling layer
\input{Figures/Figures CNN/Single_Pooling_Layer}

%Backpropagation
\input{Figures/Figures CNN/Back_propagation}

\newpage


